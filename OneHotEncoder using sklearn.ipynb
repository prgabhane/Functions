{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef71631",
   "metadata": {},
   "source": [
    "## OneHotEncoder using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a73152",
   "metadata": {},
   "source": [
    "### **Function takes Training and Test Datasets as arguements and returns One Hot Encoded Test Dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5b3ad",
   "metadata": {},
   "source": [
    "### **ohe_fit_transform function **has been created as an** alternative to get_dummies function **used **for ONE HOT ENCODING.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67d26e",
   "metadata": {},
   "source": [
    "**Limitations of get_dummies:**\n",
    "\n",
    "1. If Training Dataset has 'n' cardinal values for any categorical column, it creates 'n' or 'n-1'(in case of dropfirst) dummy columns as per **ONE HOT ENCODING**.\n",
    "2. Due to the above, modified Training Dataset will have original no. of columns + above dummy columns.   \n",
    "3. Assume that the model has been trained on the above Dataset. \n",
    "4. Now, suppose that the future dataset for prediction has less than 'n' cardinal values.\n",
    "5. Using get_dummies function, the modified future Dataset (Test Data) will have number of columns different from that of Training Dataset.\n",
    "6. Due to the discrepancy in number of columns, Test Data can't be transformed using the above model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5d904",
   "metadata": {},
   "source": [
    "**Acknowledgment**: I am thankful to scikit-learn.org for providing the necessary packages and functions at the following link based on which this function has been created.\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4373765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_fit_transform(Train_data,Test_data):\n",
    "    \n",
    "    '''\n",
    "    ohe_fit_transform function has been created \n",
    "    as an alternative to get_dummies function used for ONE HOT ENCODING.\n",
    "    \n",
    "    It uses sklearn package's OneHotEncoder, fit and transform function.\n",
    "    \n",
    "    Limitations of get_dummies:\n",
    "    \n",
    "    1. If Training Dataset has 'n' cardinal values for any categorical column,\n",
    "       it creates 'n' or 'n-1'(in case of dropfirst) dummy columns as per ONE HOT ENCODING.\n",
    "    2. Due to the above, modified Training Dataset will have original no. of columns + above dummy columns.   \n",
    "    3. Assume that the model has been trained on the above Dataset.\n",
    "    4. Now, suppose that the future dataset for prediction has less than 'n' cardinal values.\n",
    "    5. Using get_dummies function, the modified future Dataset (Test Data) will have number of columns \n",
    "       different from that of Training Dataset.\n",
    "    6. Due to the discrepancy in number of columns, Test Data can't be transformed using the above model fit.\n",
    "    \n",
    "    Not finding any readymade function that would take Datasets with categorical columns as inputs\n",
    "    and resolve the above limitations, a small ohe_fit_transform has been written \n",
    "    that takes in two data sets as arguements - Train_data & Test_data.\n",
    "    \n",
    "    Function returns new DataSet with dummies for the Test Dataset.\n",
    "    \n",
    "    For creating the model, pass only Training Dataset against both the arguements in the function as follows:\n",
    "    \n",
    "    OHE_Train_data = ohe_fit_transform (Train_data = Training_data, Test_data = Training_data)\n",
    "    \n",
    "    Replace second arguement with future data for prediction against the arguement for Test_data as follows:\n",
    "    \n",
    "    OHE_Future_data = ohe_fit_transform (Train_data = Training_data, Test_data = Future_data)\n",
    "    \n",
    "    Acknowledgment: I am thankful to scikit-learn.org for providing the necessary packages and functions\n",
    "    at the following link based on which this function has been created.\n",
    "    \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    #Creating list of columns in the Training Dataset with \"object\" dtype for One Hot Encoding\n",
    "    cat_cols = [col for col in Train_data.columns if Train_data[col].dtype == np.object]\n",
    "\n",
    "    # Store such categorical columns of Train Dataset in a newly formed DataFrame\n",
    "    Train_data_cat_cols = Train_data[cat_cols] \n",
    "\n",
    "    # Fitting the Train Data for One Hot Encoding\n",
    "    ohe_enc = OneHotEncoder(drop='first').fit(Train_data_cat_cols) \n",
    "    \n",
    "    # Stores list of newly formed features\n",
    "    cat_labels_new = list(ohe_enc.get_feature_names(cat_cols))\n",
    "    \n",
    "    # \n",
    "    Test_data_cat_cols = Test_data[cat_cols] \n",
    "\n",
    "    enc_df = pd.DataFrame(ohe_enc.transform(Test_data_cat_cols).toarray())\n",
    "    enc_df=enc_df.astype(int)\n",
    "\n",
    "    enc_cols = enc_df.columns.to_list()\n",
    "\n",
    "    columns_dict = dict(zip(enc_cols,cat_labels_new))\n",
    "    enc_df.rename(columns = columns_dict,inplace=True)\n",
    "    \n",
    "    Test_data_temp = Test_data.copy()\n",
    "\n",
    "    Test_data_temp.drop(cat_cols,axis=1,inplace=True)\n",
    "    Test_data_temp = Test_data_temp.join(enc_df)\n",
    "    \n",
    "    return Test_data_temp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
